{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","colab":{"name":"Copy of lab_gan_todo.ipynb","provenance":[{"file_id":"1IViv-qwqO3GFtCicoXR-r5dN2g9siKlH","timestamp":1624864149441}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"MbRVQ73oRVAO"},"source":["# DCGAN + conditional DCGAN\n","\n","\n","In this notebook will learn about Generative Adversarial Networks by implementing a DCGAN to generate images from noise, followed by a conditional DCGAN.\n","\n","**Important:** Set the Colab environment to run on GPU\n","\n","**Notebook created by [Daniel Fojo](https://www.linkedin.com/in/daniel-fojo/) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) in [UPC School](https://www.talent.upc.edu/ing/) (2020).**\n","\n"]},{"cell_type":"code","metadata":{"id":"CsHkiwksqPPa"},"source":["import torch\n","from torch import nn, optim\n","from torchvision import transforms, datasets, utils\n","from PIL import Image\n","import numpy as np\n","import math\n","from IPython.display import display\n","from tqdm import tqdm\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_wpixTJ9fde"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"TST4RuP9qPPc"},"source":["num_epochs = 15\n","\n","lr = 0.0002\n","betas = (0.5, 0.999)\n","\n","noise_size = 100\n","batch_size = 128\n","num_val_samples = 25\n","num_classes = 10\n","num_input_channels = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1AaRIWR9L5m"},"source":["## Dataset\n","Download and prepare dataset\n"]},{"cell_type":"code","metadata":{"id":"g-f8510PqPPd"},"source":["train_transforms = transforms.Compose(\n","            [   \n","                transforms.Resize(32),\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5,), (.5,))\n","            ])\n","dataset = datasets.MNIST(root='data', train=True, transform=train_transforms, download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDFqjh4T9a7W"},"source":["## Data Loader\n","Create a data loader for the MNIST dataset"]},{"cell_type":"code","metadata":{"id":"Uv6OtrXyqPPe"},"source":["dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--drGQMaGeop"},"source":["# DCGAN"]},{"cell_type":"markdown","metadata":{"id":"MFEBhsZb96T7"},"source":["## Networks\n","First, lets define our simple generator"]},{"cell_type":"markdown","metadata":{"id":"dD8ms_VzNmWn"},"source":["### Exercise 1: Generator\n","\n","The generator takes random noise as input and gives an image as output. Your exercise is to create the generator model.\n","\n","It should follow these guidelines:\n","* The input will be a vector with random noise of size `noise_size`\n","* You should first apply a fully connected with output size 512\\*4\\*4 (channels\\*height\\*width)\n","* Then you should apply 3 blocks of:\n","    * TransposedConvolution with kernel size 4, stride 2 and padding 1. For the first block, the output channels should be 256 and for the second block, the output channels should be 128. For the third block, the output channels should be the correct one to generate images of the dataset.\n","    * BatchNorm2d except for the last block.\n","    * ReLU activation for the first 2 blocks and Tanh for the third block.\n","\n","**Hint**: Remember to use reshape where necessary"]},{"cell_type":"code","metadata":{"id":"vrnCU0vaqPPg"},"source":["class Generator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","      \n","        # TODO: Create the Fully connected layer using nn.Linear\n","        self.fc = nn.Linear(noise_size, ...) \n","        # TODO: Create the First block using nn.Sequential with ConvTranspose2d, BatchNorm2d and activation\n","        self.convt1 =nn.Sequential(  ## self.convt1 =...\n","            nn.ConvTranspose2d(..., bias=False), # [256, 8, 8] \n","            nn.BatchNorm2d(256), #it has the number of features as a parameter.\n","            nn.ReLU(),\n","        )\n","        # TODO: Create the Second block using nn.Sequential with ConvTranspose2d, BatchNorm2d and activation\n","        self.convt2 =self.convt2 = nn.Sequential( ## self.convt2 =...\n","            nn.ConvTranspose2d(..., bias=False),  # [128, 16, 16] \n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","        )\n","\n","        # TODO: Create the Third block using nn.Sequential with ConvTranspose2d, and activation\n","        self.convt3 = self.convt3 = nn.Sequential( ## self.convt3 =...\n","            nn.ConvTranspose2d(..., bias=False),  # [1, 32, 32] \n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        # TODO: Define the forward of the network, x is a random noise, it should be forwarded through the fully connected, then reshaped and finally forwarded throught the conv layers\n","        x = ...\n","        x = x.reshape(...)\n","        x = ...\n","        x = ...\n","        x = ...\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LnSOu07Q-FLh"},"source":["Similarly lets define a simple discriminator"]},{"cell_type":"markdown","metadata":{"id":"9BQFM-vIPHvj"},"source":["### Exercise 2: Discriminator\n","\n","The discriminator takes an image as input and classifies it between Real or Fake (1 or 0). Your exercise is to create the discriminator model.\n","\n","It should follow these guidelines:\n","* The input will be an image of size `[num_input_channels, 32, 32]`\n","* You should apply 3 blocks of:\n","    * Convolution with kernel size 4, stride 2 and padding 1. The output channels should be 128, 256 and 512.\n","    * BatchNorm2d except for the first block.\n","    * LeakyReLU activation (alpha=0.2)\n","* Then you should apply a fully connected with input size 512\\*4\\*4 (channels\\*height\\*width) and the correct output size and activation for binary classification\n","\n","\n","**Hint**: Remember to use reshape/flatten where necessary"]},{"cell_type":"code","metadata":{"id":"-xWomYcyqPPh"},"source":["class Discriminator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        \n","        # TODO: Create the First block using nn.Sequential with Conv2d and activation\n","        self.conv1 = nn.Sequential( ## self.conv1 =...\n","            nn.Conv2d(num_input_channels,..., bias=False),\n","            nn.LeakyReLU(0.2),\n","        )\n","        # TODO: Create the Second block using nn.Sequential with Conv2d, BatchNorm2d and activation\n","        self.conv2 = nn.Sequential( ## self.conv2 =...\n","            nn.Conv2d(..., bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2),\n","        )\n","        # TODO: Create the third block using nn.Sequential with Conv2d, BatchNorm2d and activation\n","        self.conv3 = nn.Sequential( ## self.conv3 =...\n","            nn.Conv2d(..., bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2),\n","        )\n","        # TODO: Create the fully connected block using nn.Sequential with Linear and activation\n","        self.fc = self.fc = nn.Sequential( ## self.fc =...\n","            nn.Linear(...),\n","            nn.Sigmoid(), #binary classification - real vs false\n","        )\n","\n","    def forward(self, x):\n","        # TODO: Define the forward of the network, x is an image [num_input_channels, 32, 32], it should be forwarded through the conv layers, the flattened and forwarded through the fully connected\n","        x = ...\n","        x = ...\n","        x = ...\n","        x = x.flatten(...)\n","        x = ...\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Fgg5NWBqPPi"},"source":["generator = Generator().to(device)\n","optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n","\n","discriminator = Discriminator().to(device)\n","optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n","\n","criterion = nn.BCELoss()\n","\n","def init_weights(m):\n","    if type(m) in {nn.Conv2d, nn.ConvTranspose2d, nn.Linear}:\n","        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","        if m.bias != None:\n","            torch.nn.init.constant_(m.bias, 0.0)\n","    if type(m) == nn.BatchNorm2d:\n","        nn.init.normal_(m.weight, 1.0, 0.02)\n","        nn.init.constant_(m.bias, 0)\n","\n","generator.apply(init_weights)\n","discriminator.apply(init_weights);\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNKQKA4FfCL7"},"source":["## Train function"]},{"cell_type":"markdown","metadata":{"id":"ryDTioLaSd_t"},"source":["### Exercise 3: Train\n","\n","Complete the code. Take into account which labels should be used at each step of the training."]},{"cell_type":"code","metadata":{"id":"kg-Sx3n-qPPk"},"source":["def train_batch(real_samples, generator, discriminator, optimizer_g, optimizer_d):\n","\n","    generator.train()\n","    discriminator.train()\n","    \n","    current_batch_size = real_samples.shape[0]\n","    # TODO: Define the labels for the real and fake images so the discriminator can learn, of size [batch_size,1]\n","    label_real = torch.xxxxx(current_batch_size, 1, device=device) \n","    label_fake = torch.xxxxx(current_batch_size, 1, device=device)\n","\n","    ####################\n","    # OPTIMIZE GENERATOR\n","    ####################\n","\n","    # Reset gradients\n","    optimizer_g.zero_grad()\n","\n","    # Generate fake samples\n","    z = torch.randn(current_batch_size, noise_size, device=device) \n","    fake_samples = generator(z) \n","    \n","    # Evaluate the generated samples with the discriminator\n","    predictions_g_fake = discriminator(fake_samples) \n","    # Calculate error with respect to what the generator wants\n","    loss_g = criterion(predictions_g_fake, label_real) \n","        \n","    # Backpropagate\n","    loss_g.backward() \n","    \n","    # Update weights (do a step in the optimizer)\n","    optimizer_g.step() \n","    \n","    ####################\n","    # OPTIMIZE DISCRIMINATOR\n","    ####################\n","\n","    fake_samples = fake_samples.detach() #Let's detach them so they can be forwarded though the discriminator model\n","    # Reset gradients\n","    optimizer_d.zero_grad() #\n","\n","    # Calculate discriminator prediction for real samples\n","    predictions_d_real = discriminator(real_samples) #\n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_real = criterion(predictions_d_real, label_real) \n","\n","    # Calculate discriminator loss for fake samples\n","    predictions_d_fake = discriminator(fake_samples) \n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_fake = criterion(predictions_d_fake, label_fake) \n","    \n","    # Total discriminator loss\n","    loss_d = (loss_d_real + loss_d_fake) / 2\n","    loss_d.backward()\n","\n","    # Update weights (do a step in the optimizer)\n","    optimizer_d.step() \n","\n","    return loss_g.item(), loss_d.item()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VbBC3H3j0Yal"},"source":["## Evaluation function"]},{"cell_type":"code","metadata":{"id":"-flafuehqPPl"},"source":["@torch.no_grad()\n","def evaluate(generator, z_val):\n","    generator.eval()\n","    fake_samples = generator(z_val).cpu()\n","    # select a sample or create grid if img is a batch\n","    nrows = int(math.sqrt(fake_samples.shape[0]))\n","    img = utils.make_grid(fake_samples, nrow=nrows)\n","\n","    # unnormalize\n","    img = (img*0.5 + 0.5)*255\n","\n","    # to numpy\n","    image_numpy = img.numpy().astype(np.uint8)\n","    image_numpy = np.transpose(image_numpy, (1, 2, 0))\n","    return Image.fromarray(image_numpy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iWS0uvRJEHGd"},"source":["## Train loop"]},{"cell_type":"code","metadata":{"id":"ara-YyJCqPPm"},"source":["z_val = torch.randn(num_val_samples, noise_size, device=device)\n","\n","for epoch in range(num_epochs):\n","\n","    for i, (real_samples, labels) in enumerate(dataloader):\n","        real_samples = real_samples.to(device)\n","        loss_g, loss_d = train_batch(real_samples, generator, discriminator, optimizer_g, optimizer_d)\n","\n","        if i % 100 == 0:\n","            fake_images = evaluate(generator, z_val)\n","            display(fake_images)\n","\n","            # Show current loss\n","            print(f\"epoch: {epoch+1}/{num_epochs} batch: {i+1}/{len(dataloader)} G_loss: {loss_g}, D_loss: {loss_d}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FgkBXj-9Jgq"},"source":["# Conditional GAN"]},{"cell_type":"markdown","metadata":{"id":"YdXFJ_B3E0l1"},"source":["## Networks"]},{"cell_type":"markdown","metadata":{"id":"bbf_CtNvS2uT"},"source":["### Exercise 4: Generator\n","\n","We will now modify the generator from before to a conditional generator. To do it, we will concatenated the input to the convolutions with an embedding of the label we want to generate.\n","\n","Complete the forward method. To do it, use the embedding layer with the label, and then use `torch.cat` to concatenate the label as a channel (after the corresponding `reshape`)\n","\n","**Hint**: The embedding is concatenated as a new channel."]},{"cell_type":"code","metadata":{"id":"KCyygM86qPPn"},"source":["class ConditionalGenerator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","\n","        # TODO: Create the Fully connected layer using nn.Linear\n","        self.fc = self.fc = nn.Linear(noise_size, ...) \n","\n","        self.embedding = nn.Embedding(num_classes, 4*4) #what we will have to add the condition\n","\n","        # TODO: Create the First block using nn.Sequential with ConvTranspose2d, BatchNorm2d and activation\n","        self.convt1 =nn.Sequential(  #It is important that we add +1 to the first number of channels, since we have an extra channel that will be concatenated\n","            nn.ConvTranspose2d(..., bias=False), # [256, 8, 8] \n","            nn.BatchNorm2d(256), #it has the number of features as a parameter.\n","            nn.ReLU(),\n","        )\n","        # TODO: Create the Second block using nn.Sequential with ConvTranspose2d, BatchNorm2d and activation\n","        self.convt2 =self.convt2 = nn.Sequential( ## self.convt2 =...\n","            nn.ConvTranspose2d(..., bias=False),  # [128, 16, 16] \n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","        )\n","\n","        # TODO: Create the Third block using nn.Sequential with ConvTranspose2d, and activation\n","        self.convt3 = self.convt3 = nn.Sequential( ## self.convt3 =...\n","            nn.ConvTranspose2d(..., bias=False),  # [1, 32, 32] \n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x, label):\n","        # TODO: Define the forward of the generator\n","        x = ... #First forward through the fully connected network\n","        x = x.reshape(...) #reshape it so it can be an image of [bs, 512,4,4]\n","\n","        emb = self.embedding(label).view(-1, 1, 4, 4) #This is done to be able to concatenate the lable with the noise image\n","        x = torch.cat([x, emb], dim=1) ## x = torch.cat(...)\n","\n","        x = self.convt1(x) ## x = ... #now we can forward it though the 3 convolutional layers\n","        x = self.convt2(x) ## x = ...\n","        x = self.convt3(x) ## x = ...\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZhtPC283Tbkv"},"source":["### Exercise 5: Discriminator\n","\n","We will now modify the discriminator from before to a conditional discriminator. To do it, we will concatenated the input image with an embedding of the label we want to generate.\n","\n","Complete the forward method. To do it, use the embedding layer with the label, and then use `torch.cat` to concatenate the label as a channel (after the corresponding `reshape`)\n","\n","**Hint**: The embedding is concatenated as a new channel."]},{"cell_type":"code","metadata":{"id":"0Vmix7PGqPPo"},"source":["class ConditionalDiscriminator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(num_classes, 32*32)\n","\n","        # TODO: Create the First block using nn.Sequential with Conv2d and activation, remember to add +1 a the number of input channels\n","        self.conv1 = nn.Sequential( ## self.conv1 =...\n","            nn.Conv2d(in_channels=..., out_channels=..., kernel_size=..., stride=..., padding=..., bias=False),\n","            nn.LeakyReLU(0.2)\n","        )\n","        # TODO: Create the Second block using nn.Sequential with Conv2d, BatchNorm2d and activation\n","        self.conv2 = nn.Sequential( ## self.conv2 =...\n","            nn.Conv2d(..., bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2)\n","        )\n","        # TODO: Create the third block using nn.Sequential with Conv2d, BatchNorm2d and activation\n","        self.conv3 = nn.Sequential( ## self.conv3 =...\n","            nn.Conv2d(..., bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2)\n","        )\n","        # TODO: Create the fully connected block using nn.Sequential with Linear and activation\n","        self.fc = nn.Sequential( ## self.fc =...\n","            nn.Linear(...),\n","            nn.Sigmoid() #binary classification - real vs false\n","        )\n","\n","    def forward(self, x, label):\n","        # TODO: Define the forward of the discriminator\n","        emb = self.embedding(label).view(-1, 1, 32, 32) #to be able to concatenate it with the input image\n","        x = torch.cat(...)\n","\n","        x = self.conv1(x)  #now we can forward it though the 3 convolutional layers\n","        x = self.conv2(x) \n","        x = self.conv3(x) \n","        x = x.flatten(...)  #flatten to forward it to the fully connected\n","        x = self.fc(x) # now we can forward it though the fully connected\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"51gYq1dYqPPo"},"source":["generator = ConditionalGenerator().to(device)\n","optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n","\n","discriminator = ConditionalDiscriminator().to(device)\n","optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n","\n","criterion = nn.BCELoss()\n","\n","def init_weights(m):\n","    if type(m) in {nn.Conv2d, nn.ConvTranspose2d, nn.Linear}:\n","        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","        if m.bias != None:\n","            torch.nn.init.constant_(m.bias, 0.0)\n","    if type(m) == nn.BatchNorm2d:\n","        nn.init.normal_(m.weight, 1.0, 0.02)\n","        nn.init.constant_(m.bias, 0)\n","\n","generator.apply(init_weights)\n","discriminator.apply(init_weights);\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85_bncGME4VC"},"source":["## Train function"]},{"cell_type":"code","metadata":{"id":"cEr8sugCqPPp"},"source":["def train_batch_conditional(real_samples, real_labels, generator, discriminator, optimizer_g, optimizer_d):\n","\n","    generator.train()\n","    discriminator.train()\n","    current_batch_size = real_samples.shape[0]\n","    # Define the labels for the real and fake images so the discriminator can learn, of size [batch_size,1]\n","    label_real = torch.xxxxx(current_batch_size, 1, device=device) \n","    label_fake = torch.xxxxx(current_batch_size, 1, device=device) \n","\n","    ####################\n","    # OPTIMIZE GENERATOR\n","    ####################\n","\n","    # Reset gradients\n","    optimizer_g.zero_grad() \n","\n","    # Generate fake samples\n","    z = torch.randn(current_batch_size, noise_size, device=device) \n","    fake_labels = torch.randint(0, 10, size=(current_batch_size, 1), device=device) #we dfine the int to which we will condition the network\n","    fake_samples = generator(z, fake_labels) \n","    \n","    # Evaluate the generated samples with the discriminator\n","    predictions_g_fake = discriminator(fake_samples, fake_labels) \n","\n","    # Calculate error with respect to what the generator wants\n","    loss_g = criterion(predictions_g_fake, label_real) \n","\n","    # Backpropagate\n","    loss_g.backward() \n","    \n","    # Update weights\n","    optimizer_g.step() \n","\n","    ####################\n","    # OPTIMIZE DISCRIMINATOR\n","    ####################\n","\n","    fake_samples = fake_samples.detach()\n","    # Reset gradients\n","    optimizer_d.zero_grad() \n","\n","    # Calculate discriminator prediction for real samples\n","    predictions_d_real = discriminator(real_samples, real_labels) \n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_real = criterion(predictions_d_real, label_real) \n","\n","    # Calculate discriminator loss for fake samples\n","    predictions_d_fake = discriminator(fake_samples, fake_labels) \n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_fake = criterion(predictions_d_fake, label_fake) \n","    \n","    # Total discriminator loss\n","    loss_d = (loss_d_real + loss_d_fake) / 2\n","\n","    # Backpropagate\n","    loss_d.backward() \n","\n","    # Update weights\n","    optimizer_d.step() \n","\n","    return loss_g.item(), loss_d.item()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7cZiJBr4E6P_"},"source":["## Evaluation function"]},{"cell_type":"code","metadata":{"id":"dZdZ0jHBqPPq"},"source":["@torch.no_grad()\n","def evaluate_conditional(generator, z_val, labels_val):\n","    generator.eval()\n","    fake_samples = generator(z_val, labels_val).cpu()\n","    # select a sample or create grid if img is a batch\n","    nrows = int(math.sqrt(fake_samples.shape[0]))\n","    img = utils.make_grid(fake_samples, nrow=nrows)\n","\n","    # unnormalize\n","    img = (img*0.5 + 0.5)*255\n","\n","    # to numpy\n","    image_numpy = img.numpy().astype(np.uint8)\n","    image_numpy = np.transpose(image_numpy, (1, 2, 0))\n","    return Image.fromarray(image_numpy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w-g63Js1E9N7"},"source":["## Train loop"]},{"cell_type":"code","metadata":{"id":"0A3Q3rJoqPPq"},"source":["from itertools import cycle\n","\n","z_val = torch.randn(num_val_samples, noise_size, device=device)\n","labels_cycle = cycle(range(num_classes))\n","labels_val = torch.tensor([next(labels_cycle) for i in range(num_val_samples)], device=device).unsqueeze(1) #the labels will be a cycle from 0 to 9\n","for epoch in range(num_epochs):\n","\n","    for i, (real_samples, real_labels) in enumerate(dataloader):\n","        real_samples = real_samples.to(device)\n","        real_labels = real_labels.unsqueeze(1).to(device)\n","        loss_g, loss_d = train_batch_conditional(real_samples, real_labels, generator, discriminator, optimizer_g, optimizer_d)\n","\n","        if i % 100 == 0:\n","            fake_images = evaluate_conditional(generator, z_val, labels_val)\n","            display(fake_images)\n","\n","            # Show current loss\n","            print(f\"epoch: {epoch+1}/{num_epochs} batch: {i+1}/{len(dataloader)} G_loss: {loss_g}, D_loss: {loss_d}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJ7BvLZaqPPr"},"source":["#You can play and visualize different numbers\n","number_chosen = 1\n","z_val = torch.randn(num_val_samples, noise_size, device=device)\n","number_chosen_torch = torch.tensor([number_chosen for i in range(num_val_samples)], device=device).unsqueeze(1)\n","\n","images_number_chosen = evaluate_conditional(generator, z_val, number_chosen_torch)\n","display(images_number_chosen)"],"execution_count":null,"outputs":[]}]}