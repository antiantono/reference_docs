{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_colwidth = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/philipharman/Dropbox/data_science/realtime_data_analysis\r\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "DATAPATH = \"../../../Desktop/RT-activity-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"StructuredStreamingApplication\").getOrCreate()\n",
    "schema = spark.read.json(DATAPATH).limit(100).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Arrival_Time,LongType,true),StructField(Creation_Time,LongType,true),StructField(Device,StringType,true),StructField(Index,LongType,true),StructField(Model,StringType,true),StructField(User,StringType,true),StructField(gt,StringType,true),StructField(x,DoubleType,true),StructField(y,DoubleType,true),StructField(z,DoubleType,true)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Schema specification is not necessary for a spark DF, but IS necessary for stream\n",
    "# maxFilePerTrigger is used to specify how many files to pass in each trigger\n",
    "\n",
    "streaming = spark.readStream.schema(schema).option(\"maxFilesPerTrigger\", 1)\\\n",
    ".json(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection and filtering\n",
    "# Streaming query name has to be provided, and should be unique\n",
    "\n",
    "simpleTransform = streaming.withColumn(\"stairs\", f.expr(\"gt like '%stairs%'\"))\\\n",
    ".where(\"stairs\")\\\n",
    ".where(\"gt is not null\")\\\n",
    ".select(\"gt\", \"model\", \"arrival_time\", \"creation_time\")\\\n",
    ".writeStream\\\n",
    ".queryName(\"simple_transform\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"append\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+-------------------+\n",
      "|      gt| model| arrival_time|      creation_time|\n",
      "+--------+------+-------------+-------------------+\n",
      "|stairsup|nexus4|1424687983801|1424689829851420571|\n",
      "|stairsup|nexus4|1424687984163|1424687982169917952|\n",
      "|stairsup|nexus4|1424687984571|1424687982572835163|\n",
      "|stairsup|nexus4|1424687984972|1424687982975667195|\n",
      "|stairsup|nexus4|1424687985370|1424687983379305060|\n",
      "+--------+------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM simple_transform\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation\n",
    "deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\\\n",
    ".drop(\"avg(Arrival_time)\")\\\n",
    ".drop(\"avg(Creation_Time)\")\\\n",
    ".drop(\"avg(Index)\")\\\n",
    ".writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|5.785091065758492E-4|-0.00602935633295...|-0.01016035339884...|\n",
      "|      null|  null|-0.00828515628466...|-0.00109878056991...|0.002830288476428504|\n",
      "|stairsdown|  null|0.022019979117652917|-0.03204555603934...| 0.12001405503192161|\n",
      "|       sit|  null|-5.41473832946038E-4|2.821068722282605E-4|-2.23854002210174...|\n",
      "|stairsdown|nexus4|0.022019979117652917|-0.03204555603934...| 0.12001405503192161|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM device_counts\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>model</th>\n",
       "      <th>avg(x)</th>\n",
       "      <th>avg(y)</th>\n",
       "      <th>avg(z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stairsdown</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.032046</td>\n",
       "      <td>0.120014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bike</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>null</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gt   model    avg(x)    avg(y)    avg(z)\n",
       "4  stairsdown  nexus4  0.022020 -0.032046  0.120014\n",
       "5        bike  nexus4  0.022845 -0.008633 -0.082440\n",
       "6        null  nexus4 -0.008285 -0.001099  0.002830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>model</th>\n",
       "      <th>avg(x)</th>\n",
       "      <th>avg(y)</th>\n",
       "      <th>avg(z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stairsdown</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.032046</td>\n",
       "      <td>0.120014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bike</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>null</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gt   model    avg(x)    avg(y)    avg(z)\n",
       "4  stairsdown  nexus4  0.022020 -0.032046  0.120014\n",
       "5        bike  nexus4  0.022845 -0.008633 -0.082440\n",
       "6        null  nexus4 -0.008285 -0.001099  0.002830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>model</th>\n",
       "      <th>avg(x)</th>\n",
       "      <th>avg(y)</th>\n",
       "      <th>avg(z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stairsdown</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.032046</td>\n",
       "      <td>0.120014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bike</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>null</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gt   model    avg(x)    avg(y)    avg(z)\n",
       "4  stairsdown  nexus4  0.022020 -0.032046  0.120014\n",
       "5        bike  nexus4  0.022845 -0.008633 -0.082440\n",
       "6        null  nexus4 -0.008285 -0.001099  0.002830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>model</th>\n",
       "      <th>avg(x)</th>\n",
       "      <th>avg(y)</th>\n",
       "      <th>avg(z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stairsdown</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.032046</td>\n",
       "      <td>0.120014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bike</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>null</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gt   model    avg(x)    avg(y)    avg(z)\n",
       "4  stairsdown  nexus4  0.022020 -0.032046  0.120014\n",
       "5        bike  nexus4  0.022845 -0.008633 -0.082440\n",
       "6        null  nexus4 -0.008285 -0.001099  0.002830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>model</th>\n",
       "      <th>avg(x)</th>\n",
       "      <th>avg(y)</th>\n",
       "      <th>avg(z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stairsdown</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.032046</td>\n",
       "      <td>0.120014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bike</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>null</td>\n",
       "      <td>nexus4</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gt   model    avg(x)    avg(y)    avg(z)\n",
       "4  stairsdown  nexus4  0.022020 -0.032046  0.120014\n",
       "5        bike  nexus4  0.022845 -0.008633 -0.082440\n",
       "6        null  nexus4 -0.008285 -0.001099  0.002830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live view ended...\n"
     ]
    }
   ],
   "source": [
    "# spark.sql can be used to request how the query is performing\n",
    "\n",
    "from time import sleep\n",
    "for x in range(0, 5):\n",
    "    display(spark.sql(f\"SELECT * from device_counts\").toPandas().dropna().head(3))\n",
    "    sleep(1)\n",
    "    \n",
    "    #clear_output(wait=True)\n",
    "else:\n",
    "    print(\"Live view ended...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "static= spark.read.json(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|           x|           y|           z|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "|1424686735090|1424686733090638193|nexus4_1|   18|nexus4|   g|stand| 3.356934E-4|-5.645752E-4|-0.018814087|\n",
      "|1424686735292|1424688581345918092|nexus4_2|   66|nexus4|   g|stand|-0.005722046| 0.029083252| 0.005569458|\n",
      "|1424686735500|1424686733498505625|nexus4_1|   99|nexus4|   g|stand|   0.0078125|-0.017654419| 0.010025024|\n",
      "|1424686735691|1424688581745026978|nexus4_2|  145|nexus4|   g|stand|-3.814697E-4|   0.0184021|-0.013656616|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins - using a join of a static dataframe on a streaming one\n",
    "historicalAgg = static.groupBy(\"gt\", \"model\").avg()\n",
    "deviceModelStats = streaming.drop(\"Arrival_Time\", \"Creation_Time\", \"Index\")\\\n",
    ".cube(\"gt\", \"model\").avg()\\\n",
    ".join(historicalAgg, [\"gt\", \"model\"])\\\n",
    ".writeStream.queryName(\"device_counts_join\").format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|   avg(Arrival_Time)|  avg(Creation_Time)|        avg(Index)|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      bike|nexus4|0.022964785314061254|-0.00883802096885...|-0.08280852157940341|1.424751134339985...|1.424752127369587...| 326459.6867328154|0.022688759550866796|-0.00877912156368...| -0.0825100166341234|\n",
      "|      null|nexus4|-0.00861985194739502|-0.00118695209268...|0.002615053985997819|1.424749002876339...|1.424749919482128...| 219276.9663669269|-0.00847688860109...|-7.30455258739192...|0.003090601491419929|\n",
      "|stairsdown|nexus4|0.021940372352212245|-0.03145080962306262| 0.12130916214488122|1.424744591412857...|1.424745503635638...|230452.44623187225| 0.02161390866916545|-0.03249018824752...| 0.12035922691504071|\n",
      "|     stand|nexus4|-3.05486659249782...|2.950288503954850...|2.881832138007999E-4|1.424743637921210...|1.424744579547463...|31317.877585550017|-3.11082189691709...|3.218461665975353E-4|2.141300040636499...|\n",
      "|      walk|nexus4|-0.00383499087252...|0.001711204986843...|-0.00152407149813...|1.424746420641790...|1.424747351060674...|149760.09974990616|-0.00390116006094...|0.001052508689953...|-6.95435553042996...|\n",
      "+----------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM device_counts_join\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "activityCounts = streaming.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x13190a710>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activityCounts.writeStream.trigger(processingTime='5 seconds')\\\n",
    ".format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x13190afd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activityCounts.writeStream.trigger(once=True)\\\n",
    ".format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Time and Stateful Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)\n",
    "static = spark.read.json(\"./activity-data\")\n",
    "streaming = spark\\\n",
    ".readStream\\\n",
    ".schema(static.schema)\\\n",
    ".option(\"maxFilesPerTrigger\", 10)\\\n",
    ".json(\"./activity-data\")\n",
    "\n",
    "streaming.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "withEventTime = streaming\\\n",
    ".selectExpr(\"*\", \"cast(cast(Creation_Time as double)/1000000000 as timestamp) as event_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x131ea1fd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tumbling Windows\n",
    "from pyspark.sql.functions import window, col\n",
    "withEventTime.groupBy(window(col(\"event_time\"), \"10 minutes\")).count()\\\n",
    ".writeStream\\\n",
    ".queryName(\"pyevents_per_window\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM pyevents_per_window\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|              window| count|\n",
      "+--------------------+------+\n",
      "|{2015-02-24 17:20...|150773|\n",
      "|{2015-02-24 18:30...|133323|\n",
      "|{2015-02-23 18:00...|100853|\n",
      "|{2015-02-23 15:50...| 99178|\n",
      "|{2015-02-24 18:00...|125679|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM pyevents_per_window\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1319ead50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregations across multiple columns\n",
    "from pyspark.sql.functions import window, col\n",
    "withEventTime.groupBy(window(col(\"event_time\"), \"10 minutes\"), \"User\").count()\\\n",
    ".writeStream\\\n",
    ".queryName(\"events_per_window\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------+\n",
      "|              window|User| count|\n",
      "+--------------------+----+------+\n",
      "|{2015-02-24 17:50...|   f|133623|\n",
      "|{2015-02-24 18:30...|   f| 33366|\n",
      "|{2015-02-24 20:20...|   e|126282|\n",
      "|{2015-02-23 20:00...|   h| 94669|\n",
      "|{2015-02-24 19:40...|   e| 67577|\n",
      "+--------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM events_per_window\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1325d7cd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sliding Windows\n",
    "from pyspark.sql.functions import window, col\n",
    "withEventTime.groupBy(window(col(\"event_time\"), \"10 minutes\", \"5 minutes\"))\\\n",
    ".count()\\\n",
    ".writeStream\\\n",
    ".queryName(\"pyevents_per_sliding_window\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|              window| count|\n",
      "+--------------------+------+\n",
      "|{2015-02-23 19:45...|107668|\n",
      "|{2015-02-24 17:20...|150773|\n",
      "|{2015-02-24 18:30...|133323|\n",
      "|{2015-02-22 06:05...|    35|\n",
      "|{2015-02-23 18:00...|100853|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM pyevents_per_sliding_window\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1319c96d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Watermarks for handling delays\n",
    "from pyspark.sql.functions import window, col\n",
    "withEventTime\\\n",
    ".withWatermark(\"event_time\", \"30 minutes\")\\\n",
    ".groupBy(window(col(\"event_time\"), \"10 minutes\", \"5 minutes\"))\\\n",
    ".count()\\\n",
    ".writeStream\\\n",
    ".queryName(\"watermarking_events\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              window|count|\n",
      "+--------------------+-----+\n",
      "|{2015-02-23 19:45...|26984|\n",
      "|{2015-02-24 17:20...|37578|\n",
      "|{2015-02-24 18:30...|33292|\n",
      "|{2015-02-22 06:05...|    6|\n",
      "|{2015-02-23 18:00...|25170|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM watermarking_events\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "withEventTime\\\n",
    ".withWatermark(\"event_time\", \"5 seconds\")\\\n",
    ".dropDuplicates([\"User\", \"event_time\"])\\\n",
    ".groupBy(\"User\")\\\n",
    ".count()\\\n",
    ".writeStream\\\n",
    ".queryName(\"pydeduplicated\")\\\n",
    ".format(\"memory\")\\\n",
    ".outputMode(\"complete\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|User|count|\n",
      "+----+-----+\n",
      "|   a|80854|\n",
      "|   b|91239|\n",
      "|   c|77155|\n",
      "|   g|91673|\n",
      "|   h|77326|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM pydeduplicated\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing and Fault Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing\n",
    "static = spark.read.json(\"./activity-data\")\n",
    "streaming = spark\\\n",
    ".readStream\\\n",
    ".schema(static.schema)\\\n",
    ".option(\"maxFilesPerTrigger\", 10)\\\n",
    ".json(\"./activity-data\")\\\n",
    ".groupBy(\"gt\")\\\n",
    ".count()\n",
    "\n",
    "query = streaming\\\n",
    ".writeStream\\\n",
    ".outputMode(\"complete\")\\\n",
    ".option(\"checkpointLocation\", \"./checkpointing/\")\\\n",
    ".queryName(\"test_python_stream\")\\\n",
    ".format(\"memory\")\\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6556e144-3df9-4473-9e0a-26c18e5da84b',\n",
       " 'runId': '5dfc0d17-2eaf-4011-8c9e-33b804ff5e99',\n",
       " 'name': 'test_python_stream',\n",
       " 'timestamp': '2021-05-31T02:25:17.391Z',\n",
       " 'batchId': 8,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'latestOffset': 12, 'triggerExecution': 12},\n",
       " 'stateOperators': [{'numRowsTotal': 7,\n",
       "   'numRowsUpdated': 0,\n",
       "   'memoryUsedBytes': 82024,\n",
       "   'numRowsDroppedByWatermark': 0,\n",
       "   'customMetrics': {'loadedMapCacheHitCount': 2800,\n",
       "    'loadedMapCacheMissCount': 0,\n",
       "    'stateOnCurrentVersionSizeBytes': 18896}}],\n",
       " 'sources': [{'description': 'FileStreamSource[file:/Users/ankitbit/Documents/Lectures/Real-Time-Data-Analysis/Tutorials/activity-data]',\n",
       "   'startOffset': {'logOffset': 7},\n",
       "   'endOffset': {'logOffset': 7},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'MemorySink', 'numOutputRows': 0}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.recentProgress[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
